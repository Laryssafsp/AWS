{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 4: Traga seu próprio contêiner para o SageMaker Studio\n",
    "\n",
    "Neste notebook, você vai criar uma imagem do Docker e um contêiner de processamento. Você vai usar uma classe **ScriptProcessor** do SDK Python do Amazon SageMaker para executar um script scikit-learn de pré-processamento no contêiner. Depois você vai validar os resultados do processamento de dados salvos no Amazon Simple Storage Service (Amazon S3)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 4.1: Configuração do ambiente\n",
    "\n",
    "Instale as bibliotecas e dependências necessárias.\n",
    "\n",
    "Você vai definir um bucket do Amazon S3 para armazenar as saídas do trabalho de processamento e também fazer com que o perfil de execução execute o trabalho de processamento do SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# add csv visualization and image-build packages\n",
    "%pip install --upgrade sagemaker-datawrangler\n",
    "%pip install sagemaker-studio-image-build \n",
    "%pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker_datawrangler\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "sagemaker_logger = logging.getLogger(\"sagemaker\")\n",
    "sagemaker_logger.setLevel(logging.INFO)\n",
    "sagemaker_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "#Execution role to run the SageMaker Processing job\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"SageMaker Execution Role: \", role)\n",
    "\n",
    "#S3 bucket to read the SKLearn processing script and writing processing job outputs\n",
    "s3 = boto3.resource('s3')\n",
    "for buckets in s3.buckets.all():\n",
    "    if 'databucket' in buckets.name:\n",
    "        bucket = buckets.name\n",
    "print(\"Bucket: \", bucket)\n",
    "\n",
    "prefix = 'scripts/data'\n",
    "S3Downloader.download(s3_uri=f\"s3://{bucket}/{prefix}/abalone_data.csv\", local_path= 'data/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 4.2: Criar um contêiner de processamento\n",
    "\n",
    "Defina e crie um contêiner do scikit-learn usando o Dockerfile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4.2.1: Criar um Dockerfile\n",
    "\n",
    "Crie um diretório do Docker e adicione o Dockerfile que cria o contêiner de processamento. Por estar criando um contêiner scikit-learn, você vai instalar o pandas e o scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
    "\n",
    "RUN pip3 install pandas scikit-learn\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ENTRYPOINT [\"python3\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4.2.2: Criar a imagem de contêiner\n",
    "\n",
    "Crie uma imagem de contêiner personalizada usando a interface de linha de comando de criação de imagem do Amazon SageMaker Studio.\n",
    "\n",
    "Usando a CLI de criação de imagem do Amazon SageMaker Studio, você pode criar imagens do Docker compatíveis com o Amazon SageMaker diretamente nos ambientes do SageMaker Studio. A CLI de criação de imagem poupa tempo e aumenta a segurança porque abstrai a criação do ambiente de criação e exige menos permissões.\n",
    "\n",
    "Navegue até o diretório que contém o Dockerfile e execute o comando de criação sm-docker. Esse comando registra em log automaticamente a saída da criação e retorna o **URI da imagem** do Docker. Essa etapa leva de 2 a 5 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "rm /usr/lib/x86_64-linux-gnu/libstdc++.so.6\n",
    "\n",
    "cp /opt/conda/lib/libstdc++.so.6 /usr/lib/x86_64-linux-gnu/libstdc++.so.6\n",
    "\n",
    "cd docker\n",
    "\n",
    "sm-docker build ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando a execução da célula terminar, vai aparecer um URI de imagem semelhante a este: *012345678910.dkr.ecr.us-east-1.amazonaws.com/sagemaker-studio-d-vcbyjgmmjzzy:data-scientist-test-user*.\n",
    "\n",
    "1. Copie o **URI da imagem** e cole-o em um editor de texto da sua escolha. \n",
    "\n",
    "Use esse **URI da imagem** para criar uma classe **ScriptProcessor**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 4.3: Executar o trabalho de processamento do SageMaker\n",
    "\n",
    "A AnyCompany Consulting está trabalhando em um projeto com um grupo ambiental sobre a idade de abalones. Abalones são um tipo de molusco ou lesma marinha. Eles querem prever a idade de espécimes vivos em vez de cortar as conchas dos animais para determinar a idade.\n",
    "\n",
    "O conjunto de dados de abalones representa uma população de mais de 4.000 espécimes. O conjunto de dados contém colunas referentes a sexo, comprimento, diâmetro, altura, peso total, peso sem a concha, peso das vísceras, peso da concha e anéis.\n",
    "\n",
    "Execute um trabalho de processamento no conjunto de dados de abalones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-data\n",
    "shape=pd.read_csv(\"data/abalone_data.csv\", header=0)\n",
    "shape.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois use a classe ScriptProcessor do SageMaker para definir e executar um script de processamento como um trabalho de processamento. Consulte [SageMaker ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor) para saber mais sobre essa classe.\n",
    "\n",
    "Para criar a classe ScriptProcessor, configure os seguintes parâmetros:\n",
    "- **base_job_name**: prefixo do nome do trabalho de processamento\n",
    "- **command**: comando a ser executado, além dos sinalizadores da linha de comando\n",
    "- **image_uri**: URI da imagem do Docker a ser usado para os trabalhos de processamento\n",
    "- **role**: função de execução do SageMaker\n",
    "- **instance_count**: número de instâncias para executar o trabalho de processamento\n",
    "- **instance_type**: tipo de instância do Amazon Elastic Compute Cloud (Amazon EC2) usado para o trabalho de processamento\n",
    "\n",
    "1. No código a seguir, substitua **REPLACE_IMAGE_URI** pelo URI do editor de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker-script-processor\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "# create a ScriptProcessor\n",
    "script_processor = ScriptProcessor(\n",
    "    base_job_name=\"own-processing-container\",\n",
    "    command=[\"python3\"],\n",
    "    image_uri=\"REPLACE_IMAGE_URI\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois use o método ScriptProcessor.run() para executar o script **sklearn_preprocessing.py** como um trabalho de processamento. Consulte [ScriptProcessor.run()](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor.run) para saber mais sobre esse método.\n",
    "\n",
    "Para executar o trabalho de processamento, configure os seguintes parâmetros:\n",
    "- **code**: caminho do script de pré-processamento \n",
    "- **inputs**: caminho dos dados de entrada do script de pré-processamento (local de entrada do Amazon S3)\n",
    "- **outputs**: caminho da saída do script de pré-processamento (local de saída do Amazon S3)\n",
    "- **arguments**: argumentos de linha de comando para o script de pré-processamento (como a taxa de divisão do teste de treinamento)\n",
    "\n",
    "O trabalho de processamento exige cerca de quatro a cinco minutos para ser concluído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing-job\n",
    "import os\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Amazon S3 path prefix\n",
    "input_raw_data_prefix = \"scripts/data\"\n",
    "output_preprocessed_data_prefix = \"scripts/data/output\"\n",
    "scripts_prefix = \"scripts/smstudiofiles\"\n",
    "logs_prefix = \"logs\"\n",
    "\n",
    "# Run the processing job\n",
    "script_processor.run(\n",
    "    code=\"s3://\" + os.path.join(bucket, scripts_prefix, \"sklearn_preprocessing.py\"),\n",
    "    inputs=[ProcessingInput(source=\"s3://\" + os.path.join(bucket, input_raw_data_prefix, \"abalone_data.csv\"),\n",
    "                            destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", \n",
    "                        source=\"/opt/ml/processing/train\",\n",
    "                        destination=\"s3://\" + os.path.join(bucket, output_preprocessed_data_prefix, \"train\")),\n",
    "        ProcessingOutput(output_name=\"test_data\", \n",
    "                        source=\"/opt/ml/processing/test\",\n",
    "                        destination=\"s3://\" + os.path.join(bucket, output_preprocessed_data_prefix, \"test\")),\n",
    "    ],\n",
    "    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    ")\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 4.4: validar os resultados do processamento de dados\n",
    "\n",
    "Valide a saída do trabalho de processamento que você executou consultando as cinco primeiras linhas dos conjuntos de dados de saída de treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view-train-dataset\n",
    "print(\"Top 5 rows from s3://{}/{}/train/\".format(bucket, output_preprocessed_data_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$output_preprocessed_data_prefix/train/train_features.csv - | head -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view-validation-dataset\n",
    "print(\"Top 5 rows from s3://{}/{}/validation/\".format(bucket, output_preprocessed_data_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$output_preprocessed_data_prefix/test/test_features.csv - | head -n5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando a execução das células terminar, vão aparecer respostas semelhantes a estas:\n",
    "\n",
    "```plain\n",
    "Top 5 rows from s3://databucket-us-east-1-xxxxxxx/scripts/data/output/validation/\n",
    "M,0.55,0.425,0.155,0.918,0.278,0.243,0.335\n",
    "I,0.5,0.4,0.12,0.616,0.261,0.143,0.194\n",
    "M,0.62,0.48,0.155,1.256,0.527,0.374,0.318\n",
    "I,0.22,0.165,0.055,0.055,0.022,0.012,0.02\n",
    "M,0.645,0.5,0.175,1.511,0.674,0.376,0.378\n",
    "```\n",
    "\n",
    "Os cabeçalhos das colunas do conjunto de dados de abalones são: sex (Infant, Male, Female), length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight e rings. A saída das pastas **train/** e **validation/** mostra os dados processados armazenados no bucket do S3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você criou um contêiner de processamento e usou o processamento do SageMaker para executar o trabalho de processamento nele.\n",
    "\n",
    "### Limpeza\n",
    "\n",
    "Você concluiu este notebook. Passe para a próxima parte do laboratório da seguinte forma:\n",
    "\n",
    "- Feche este arquivo de notebook.\n",
    "- Retorne à sessão do laboratório e continue com a **Conclusão**."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
